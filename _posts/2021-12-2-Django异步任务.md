---
layout:     post
title:      "Django 异步任务"
subtitle:   "以rabbitMQ作为中间人在Django中集成celery"
date:       2021-12-04 15:00:00
author:     "Xinbo"
header-img: "img/post-bg-universe.jpg"
tags:
    - Django
    - celery
---


### 背景

在Django开发中经常有许多耗时的任务，如调用第三方接口，邮件/短信发送等等，为了缩短请求的响应时间，最好把这些任务做成异步任务，还有一些任务需要周期执行，如数据缓存的清理，备份等工作，为了完成上述需求，需要借助一个工具。

celery是一个高效的异步消息处理框架，仅需要简单的配置就可以轻松帮我们实现异步任务和定时任务

celery通过中间人(Broker，通常选择rabbitMQ或者redis)将客户端发出的消息转交给celry worker来处理。

本文介绍了以 rabbitmq作为中间人在django中集成celery的方法

### 安装celery

> Django 版本3.2

```shell
pip3 install celery==5.0.5
pip3 install django-celery-beat==2.2.0
pip3 install django-celery-results==2.0.1
```

### 安装rabbitmq

> 也可以选择redis作为中间人

```shell
sudo apt-get install rabbitmq-server
```

新增用户

```shell
rabbitmqctl add_user ci ci
```

查看用户

```shell
rabbitmqctl list_users
```

设置管理员

```shell
rabbitmqctl set_user_tags ci administrator
```

添加虚拟环境并设置权限

```shell
rabbitmqctl add_vhost ci_backend
rabbitmqctl set_permissions -p ci_backend ci ".*" ".*" ".*"
```

重启

```shell
rabbitmqctl stop
rabbitmq-server restart
```

### 实现异步任务

在 settings.py INSTALLED_APPS 中加入celery应用

```python
INSTALLED_APPS = [
    ...
    'celery',
    'django_celery_beat',
    'django_celery_results',
   	...
]
```

执行

> 执行完后应该可以在数据库中看到新增了关于celery的数据表

```shell
python3 manage.py makemigrations
python3 manage.py migrate
```

在 settings.py 增加celery相关配置

```python
# *celey配置
CELERY_ENABLE_UTC = True
CELERY_TIMEZONE = "Asia/Shanghai"
CELERY_TASK_TRACK_STARTED = True
CELERY_TASK_TIME_LIMIT = 30 * 600
CELERY_RESULT_BACKEND = 'django-db'
CELERYD_TASK_TIME_LIMIT = 86400/4
CELERYD_TASK_SOFT_TIME_LIMIT = 86400/4
CELERY_IGNORE_RESULT = True
CELERY_BROKER_URL = 'amqp://ci:ci@172.16.20.200/ci_backend'
CELERY_ACCEPT_CONTENT = ['application/json', ]
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
```

在settings.py同级增加 **celery.py**文件

```python
from __future__ import absolute_import
import os
from celery import Celery, platforms
from celery.schedules import crontab
from kombu import Exchange, Queue

# set the default Django settings module for the 'celery' program.
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'mysite.settings')

# 使用root执行celery须配置此项，但是后续celery启动时依然会有warning
platforms.C_FORCE_ROOT = True

app = Celery('mysite')

app.config_from_object('django.conf:settings', namespace='CELERY')
app.conf.task_default_queue = 'default'
app.conf.task_default_exchange = 'default'
app.conf.task_default_routing_key = 'default'
app.conf.timezone = 'Asia/Shanghai'

# Load task modules from all registered Django app configs.
app.autodiscover_tasks()

default_exchange = Exchange('default', type='direct')

# 任务列表
app.conf.task_queues = (
    Queue(str('default'), default_exchange, routing_key=str('default')),
)

# 测试
@app.task(bind=True)
def debug_task(self):
    print('Request: {0!r}'.format(self.request))
```

修改同级的 ______init______.py

```python
from __future__ import absolute_import, unicode_literals
from .celery import app as celery_app

__all__ = ('celery_app',)
```

在django的app文件夹下新建 tasks.py 文件，如 build_info/tasks.py

```python
from celery import shared_task
import time

@shared_task
def test_timed_tasks():
    time.sleep(100)
    print("----Tasks")
```

此时关于celery的任务就写好了，下面就是激动人心的部分了

多开几个终端，在第一个终端中启动celery

> mysite是我的celery app名字

```shell
cd <your project path> celery -A mysite worker -l info
```

看到如下输出，则表明celery启动正常

> 观察 [tasks] 是否是我们前面注册的两个function
>
> celery@sz-xinbo ready. 有没有ready的这句话

```
/usr/local/lib/python3.8/dist-packages/celery/platforms.py:796: RuntimeWarning: You're running the worker with superuser privileges: this is
absolutely not recommended!

Please specify a different user using the --uid option.

User information: uid=0 euid=0 gid=0 egid=0

  warnings.warn(RuntimeWarning(ROOT_DISCOURAGED.format(

 -------------- celery@sz-xinbo v5.0.5 (singularity)
--- ***** -----
-- ******* ---- Linux-5.4.0-90-generic-x86_64-with-glibc2.29 2021-12-03 17:49:28
- *** --- * ---
- ** ---------- [config]
- ** ---------- .> app:         mysite:0x7fddc40e3520
- ** ---------- .> transport:   amqp://ci:**@172.16.20.200:5672/ci_backend
- ** ---------- .> results:
- *** --- * --- .> concurrency: 8 (prefork)
-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
--- ***** -----
 -------------- [queues]
                .> default          exchange=default(direct) key=default


[tasks]
  . build_info.tasks.test_timed_tasks
  . mysite.celery.debug_task

[2021-12-03 17:49:29,154: INFO/MainProcess] Connected to amqp://ci:**@172.16.20.200:5672/ci_backend
[2021-12-03 17:49:29,170: INFO/MainProcess] mingle: searching for neighbors
[2021-12-03 17:49:30,204: INFO/MainProcess] mingle: all alone
[2021-12-03 17:49:30,228: INFO/MainProcess] celery@sz-xinbo ready.
```

此时新开另一个终端

```shell
cd <your project path> python3 ./manage.py shell
```

通过delay的方式执行我们刚才注册的function

```shell
>>> from build_info.tasks import *
>>> res = test_timed_tasks.delay()
>>> res
<AsyncResult: 2de017ff-e0b9-4674-bf4a-b9942f075e66>
```

可以发现执行后有一个返回的任务id，此时观察celery界面，会看到已经收到任务，并在我们的延时完成后显示任务成功执行

```shell
[2021-12-03 17:50:06,661: INFO/MainProcess] Received task: build_info.tasks.test_timed_tasks[2de017ff-e0b9-4674-bf4a-b9942f075e66]
[2021-12-03 17:51:46,732: WARNING/ForkPoolWorker-8] ----Tasks
[2021-12-03 17:51:46,752: INFO/ForkPoolWorker-8] Task build_info.tasks.test_timed_tasks[2de017ff-e0b9-4674-bf4a-b9942f075e66] succeeded in 100.08967352099717s: None
```

到此，通过celery的异步任务配置就成功了

### 实现定时任务

通过celery还可以实现定时任务，依然以上文新建的任务build_info/tasks.py 中的 test_timed_tasks 为例，我们希望它隔一段时间就执行一次

在celery.py中新增定时任务

>  通过 crontab 设定每2分钟执行一次

```python
from celery.schedules import crontab

app.conf.beat_schedule = {
    'tests': {
        'task': 'build_info.tasks.test_timed_tasks',
        'schedule':crontab(minute="*/2"),
    },
}
```

启动django

```shell
python3 manage.py runserver <your ip>:<your port>
```

新开一个终端，启动worker

```shell
cd <your project path> celery -A mysite worker -l info
```

新开一个终端，启动celery beat

```shell
cd <your project path> celery -A mysite beat -l INFO
```

会看到周期性的任务发送

```shell
celery beat v5.0.5 (singularity) is starting.
__    -    ... __   -        _
LocalTime -> 2021-12-03 17:18:38
Configuration ->
    . broker -> amqp://ci:**@172.16.20.200:5672/ci_backend
    . loader -> celery.loaders.app.AppLoader
    . scheduler -> celery.beat.PersistentScheduler
    . db -> celerybeat-schedule
    . logfile -> [stderr]@%INFO
    . maxinterval -> 5.00 minutes (300s)
[2021-12-03 17:18:38,148: INFO/MainProcess] beat: Starting...
[2021-12-03 17:20:00,089: INFO/MainProcess] Scheduler: Sending due task tests (build_info.tasks.test_timed_tasks)
[2021-12-03 17:22:00,076: INFO/MainProcess] Scheduler: Sending due task tests (build_info.tasks.test_timed_tasks)
[2021-12-03 17:24:00,092: INFO/MainProcess] Scheduler: Sending due task tests (build_info.tasks.test_timed_tasks)
```

同时在worker终端看到任务执行

```shell
[2021-12-03 17:20:09,886: INFO/MainProcess] Received task: build_info.tasks.test_timed_tasks[ebabbd97-4636-45b9-afce-bf6cd6a23e35]
[2021-12-03 17:21:49,964: WARNING/ForkPoolWorker-8] ----Tasks
[2021-12-03 17:21:49,973: INFO/ForkPoolWorker-8] Task build_info.tasks.test_timed_tasks[ebabbd97-4636-45b9-afce-bf6cd6a23e35] succeeded in 100.08622614399064s: None
[2021-12-03 17:22:00,094: INFO/MainProcess] Received task: build_info.tasks.test_timed_tasks[c31f1cc3-640d-413c-b535-ee38600b64d0]
[2021-12-03 17:23:40,128: WARNING/ForkPoolWorker-8] ----Tasks
[2021-12-03 17:23:40,155: INFO/ForkPoolWorker-8] Task build_info.tasks.test_timed_tasks[c31f1cc3-640d-413c-b535-ee38600b64d0] succeeded in 100.05949019198306s: None
...
```

此时定时任务配置成功

### 部署集成

Django正式部署时采用终端的方式启动celery肯定是不现实的，需要用到celery的守护进程multi

> 通过 --beat 启动定时任务
>
> 保证pidfile路径 和 logfile 路径存在且具有写权限
>
> 启动后通过 ps aux | grep celery 可以查看到与 concurrency 数目相等的进程

```shell
cd <your project path>
celery multi start w1 -A mysite -l info --beat --pidfile=/var/run/celery/%n.pid --logfile=/var/log/celery/%n%I.log --concurrency=15
```

杀掉 celery 守护进程的方法

```shell
ps -ef | grep celery | awk '{print $2}' | xargs kill -9
```



### 参考资料

* Django使用Celery demo的官方 [github地址](https://github.com/celery/celery/tree/master/examples/django/) 
* [Celery中文手册](https://www.celerycn.io/)
* [Celery官方文档](https://docs.celeryproject.org/en/stable/)

